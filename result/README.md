# 模型測試評估報告

本報告為經過 Fine-tuning 後模型的測試結果彙整，模型用於二元分類任務，目標為辨識真假新聞。以下為測試集上的主要評估指標與混淆矩陣。

---
## 第一次fine tune 評估測試
### 📊 評估指標（Evaluation Metrics）

| 指標 (Metric) | 數值 (Score) |
|---------------|--------------|
| Accuracy      | 0.9726       |
| Precision     | 0.9546       |
| Recall        | 0.9959       |
| F1 Score      | 0.9748       |

- **Accuracy**: 整體預測正確的比例，達 97.26%，顯示模型整體表現穩定。
- **Precision**: 預測為真新聞的樣本中，有 95.46% 是實際正確的，表示模型能有效避免誤信假新聞。
- **Recall**: 實際為真新聞的樣本中，模型成功預測了 99.59%，具有極高的召回能力。
- **F1 Score**: 精準率與召回率的調和平均數，高達 97.48%，代表模型在兩者間取得良好平衡。

---

### 🔢 混淆矩陣（Confusion Matrix）

|                | 預測為假新聞 | 預測為真新聞 |
|----------------|----------------|----------------|
| **實際為假新聞** | 8323（TN）       | 474（FP）        |
| **實際為真新聞** | 41（FN）         | 9962（TP）       |

- **TN（True Negative）**: 模型正確預測為假新聞的數量。
- **FP（False Positive）**: 模型誤判假新聞為真新聞。
- **FN（False Negative）**: 模型誤判真新聞為假新聞。
- **TP（True Positive）**: 模型正確預測為真新聞的數量。

---

### 📌 總結與分析

本模型在測試集上展現出高準確率與極佳的召回率，表示其對真新聞具高度敏感性，幾乎不漏判，有利於實際應用中避免遺漏重要資訊。

雖然仍有 474 筆假新聞被誤判為真新聞，精準度略有下降，但整體 F1 Score 仍達到 0.9748，顯示模型在假新聞識別上具一定能力。

---

### 🧠 未來優化方向

- **進一步降低誤判（FP）**：可透過調整 decision threshold 或引入更多語義特徵強化判別力。
- **資料擴增與多樣性強化**：增加多來源假新聞樣本，提升模型泛化能力。
- **模型集成（Ensemble）**：結合多種語言模型以提升穩定性與精度。

---

### 📁 測試資訊

- **模型架構**: RoBERTa（已進行中文語料 MLM 預訓練後微調）
- **Tokenizer**: chinese-roberta-wwm-ext
- **測試資料量**: 18,800 筆（假新聞：8797、真新聞：10003）

---

> 📌 若需進一步查閱模型訓練細節、原始碼或重現流程，請參閱 [train/README.md](train/README.md) 或相關檔案。
