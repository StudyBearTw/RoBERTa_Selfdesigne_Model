# ğŸ“° ä¸­æ–‡çœŸå‡æ–°èè¾¨è­˜æ¨¡å‹ï¼ˆRoBERTa è‡ªè¡Œè¨­è¨ˆç‰ˆï¼‰

æœ¬å°ˆæ¡ˆç‚ºä¸€å€‹åŸºæ–¼ RoBERTa æ¶æ§‹ï¼Œä¸¦è‡ªè¡Œå¯¦ä½œçš„ä¸­æ–‡çœŸå‡æ–°èè¾¨è­˜æ¨¡å‹ã€‚æ•´é«”ç³»çµ±æ¶µè“‹å¾è³‡æ–™é è™•ç†ã€åµŒå…¥å±¤è¨­è¨ˆã€ç·¨ç¢¼å™¨å¯¦ä½œåˆ°åˆ†é¡ä»»å‹™çš„å®Œæ•´æµç¨‹ï¼Œé©åˆä½œç‚ºè‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰å¯¦å‹™æ‡‰ç”¨èˆ‡ç ”ç©¶çš„åƒè€ƒã€‚

> ğŸ“˜ æœ¬å°ˆæ¡ˆç‚ºå¤§å­¸å°ˆé¡Œæˆæœä¹‹ä¸€ï¼Œç”± [StudyBearTw](https://github.com/StudyBearTw) è£½ä½œèˆ‡ç¶­è­·ã€‚

---

## ğŸ” å°ˆæ¡ˆç°¡ä»‹

- **ä»»å‹™é¡å‹**ï¼šä¸­æ–‡æ–°èäºŒåˆ†é¡ï¼ˆçœŸ / å‡ï¼‰
- **æ¨¡å‹æ¶æ§‹**ï¼šæ¨¡ä»¿ RoBERTa è¨­è¨ˆï¼Œä¸¦ç”±é›¶é–‹å§‹å¯¦ä½œï¼ˆä¸ä¾è³´ Hugging Face ç­‰ç¾æˆæ¨¡å‹ï¼‰
- **Tokenizer**ï¼šä½¿ç”¨æ¸…è¯å¤§å­¸ä¸­æ–‡ BERT Tokenizerï¼ˆ`bert-base-chinese`ï¼‰
- **è¼¸å…¥æ ¼å¼**ï¼šæ–°èæ¨™é¡Œèˆ‡å…§æ–‡çµ„åˆç‚ºå–®ä¸€è¼¸å…¥
- **è¨“ç·´è³‡æ–™**ï¼šçœŸå¯¦ä¸–ç•Œçš„ä¸­æ–‡æ–°èè³‡æ–™é›†ï¼ˆè©³è¦‹ `data/`ï¼‰

---

## ğŸ§  æ¨¡å‹æ¶æ§‹

æœ¬æ¨¡å‹ä¸»è¦åˆ†ç‚ºä»¥ä¸‹å¹¾å€‹æ¨¡çµ„ï¼ˆçš†ç‚º `.py` æª”æ¡ˆå½¢å¼ï¼‰ï¼š

- `embeddings/`: å¯¦ä½œ RoBERTa åµŒå…¥å±¤ï¼ˆtokenã€positionã€segment embeddingï¼‰
- `encoder/`: å¤šå±¤ Transformer ç·¨ç¢¼å™¨ï¼Œæ¯å±¤å…·å‚™è‡ªæ³¨æ„åŠ›èˆ‡å‰é¥‹ç¥ç¶“ç¶²è·¯
- `model/`: çµåˆåµŒå…¥å±¤èˆ‡ç·¨ç¢¼å™¨çš„ä¸»æ¨¡å‹é¡åˆ¥
- `train.py`: æ¨¡å‹è¨“ç·´ä¸»ç¨‹å¼
- `evaluate.py`: æ¸¬è©¦èˆ‡é©—è­‰æ¨¡çµ„æ•ˆèƒ½
- `utils/`: åŒ…å« tokenizer è™•ç†ã€è³‡æ–™è®€å–ã€è¨“ç·´æµç¨‹ç­‰å·¥å…·å‡½å¼

---

## ğŸ› ï¸ å®‰è£èˆ‡åŸ·è¡Œæ–¹å¼

### 1. ç’°å¢ƒå®‰è£

è«‹å…ˆå®‰è£ Python å¥—ä»¶ï¼š

```bash
pip install -r requirements.txt
````

> âœ… å»ºè­°ä½¿ç”¨ Python 3.8+ èˆ‡ PyTorch 1.10+

### 2. è³‡æ–™æº–å‚™

å°‡è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™æ”¾å…¥ `data/` è³‡æ–™å¤¾ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```
data/
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
```

è³‡æ–™æ ¼å¼åƒè€ƒï¼š

```csv
{
  "title": "æ–°èæ¨™é¡Œ",
  "label": 1
}
```

### 3. æ¨¡å‹è¨“ç·´

```bash
python train.py
```

### 4. æ¨¡å‹è©•ä¼°

```bash
python evaluate.py
```

---

## ğŸ“ˆ æˆæ•ˆèˆ‡è©•ä¼°

* è©•ä¼°æŒ‡æ¨™ï¼šAccuracy, F1-score
* æ¸¬è©¦çµæœé¡¯ç¤ºæœ¬æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šæœ‰è‰¯å¥½çš„åˆ†é¡èƒ½åŠ›ï¼ˆè©³è¦‹ `results/`ï¼‰

---

## ğŸ“ å°ˆæ¡ˆæ¶æ§‹

```
RoBERTa_Selfdesigne_Model/
â”œâ”€â”€ embeddings/
â”œâ”€â”€ encoder/
â”œâ”€â”€ model/
â”œâ”€â”€ data/
â”œâ”€â”€ utils/
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“š åƒè€ƒè³‡æº

* [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)
* [HuggingFace Transformers (ä½œç‚ºæ¶æ§‹åƒè€ƒ)](https://github.com/huggingface/transformers)
* [Google BERT Paper](https://arxiv.org/abs/1810.04805)

---

## ğŸ“¬ è¯çµ¡æ–¹å¼

å¦‚æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿è¯çµ¡æˆ‘ï¼š

* GitHub: [StudyBearTw](https://github.com/StudyBearTw)
* Email: `studyspiderpig@gmail.com`

---

## ğŸ“œ License

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ï¼Œè©³è¦‹ `LICENSE` æª”æ¡ˆã€‚

```

---
